\documentclass[a4paper]{article}

%% Language and font encodings
\usepackage[english]{babel}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}

%% Sets page size and margins
\usepackage[a4paper,top=2.5cm,bottom=2.5cm,left=2.5cm,right=2.5cm,marginparwidth=1.75cm]{geometry}

%% Useful packages
\usepackage{multicol}
\usepackage{paralist}
\usepackage{amsmath}
\usepackage{bm,bbm}
\usepackage{amsthm}
\usepackage{graphicx}
\usepackage[colorinlistoftodos]{todonotes}
\usepackage[colorlinks=true, allcolors=blue]{hyperref}
\usepackage{nameref,cleveref}

\usepackage{../includes/MarkMathCmds}
\allowdisplaybreaks
\usepackage{mathtools}
\newcommand{\mat}[1]{{\mathrm{{#1}}}} % matrix

\usepackage{MarkBiblatexCmds}
\addbibresource{ref.bib}

\usepackage{enumitem}
\usepackage{epsdice}
\usepackage{bbm}

\input{../includes/tikzlibrarybayesnet.code.tex}
\input{../includes/tikzlibraryipe.code.tex}


\input{YingzhenMathNotations}

\newcommand{\mx}{\vm_\vx}
\newcommand{\my}{\vm_\vy}
\newcommand{\covmat}{\boldsymbol{\Sigma}}
\newcommand{\covx}{\boldsymbol{\Sigma}_{\vx\vx}}
\newcommand{\covy}{\boldsymbol{\Sigma}_{\vy\vy}}
\newcommand{\covxy}{\boldsymbol{\Sigma}_{\vx\vy}}
\newcommand{\covyx}{\boldsymbol{\Sigma}_{\vy\vx}}

\newcommand{\K}{\mathbf{K}}

\newcommand{\questionref}[1]{\Cref{#1} -- \nameref{#1}}

\newcommand{\lb}{\mathcal{L}}
\newcommand{\sumn}{\sum_{n=1}^N}

\newcommand{\dA}{\epsdice{1}}
\newcommand{\dB}{\epsdice{2}}
\newcommand{\dC}{\epsdice{3}}
\newcommand{\dD}{\epsdice{4}}
\newcommand{\dE}{\epsdice{5}}
\newcommand{\dF}{\epsdice{6}}

\theoremstyle{definition}
\newtheorem{question}{Question}

\newcommand{\courseprobstats}{\texttt{50008} \textit{Probability \& Statistics}}


\title{70015 Mathematics for Machine Learning: Exercises}
\author{Mark van der Wilk, Yingzhen Li\footnote{Many thanks to teaching assistants Carles Balsells Rodas, and Alex Spies for their solutions and improvements to the document.} \\ \texttt{\{m.vdwilk,yingzhen.li\}@imperial.ac.uk}}



\begin{document}
\maketitle
\tableofcontents



% \section{Background material}\todo{Adjust.}
% You will be expected to have a \emph{firm} understanding of Mathematics for Machine Learning. In the explanations, I will be manipulating probabilities and expectations freely, as discussed in Mathematics for Machine Learning. If steps are difficult, I encourage you to raise this on the course EdStem page, or during a Q\&A session.

% \begin{itemize}
% \item Basic probability: sample spaces, disjoint events (summation of probabilities), independent events (multiplication of probabilities). See \citet{walpole2012probability}, Ch2 (Imperial Library, or search Google for reading options).
% \item Probability densities. See \citet{mml} \S 6.2.
% \item Sum, product \& Bayes' rules. See \citet{mml} \S 6.3.
% \item Unconstrained continuous optimisation. See \citet{mml} \S 7.1.
% \item Linear algebra and matrix decompositions. See \citet{mml} ch 4 (and Chs 2 and 3 for basics).
% \item A familiarity with linear basis-function regression. See \citet{mml} ch 9.
% \end{itemize}


\section{Notation}
\subsection{Sets}
Throughout this course, we will be using some standard mathematical notation which may be unfamiliar to some. It's ultimately not that special or even crucial to the overall argument, but it is compact (which is practical), and it helps somewhat with practising with expressing things mathematically. Wikipedia has good definitions on these things too.
\begin{itemize}
\item Notation referring to sets of numbers, e.g.~the natural numbers $\mathbb N = \{0, 1, 2, \dots\}$, integers $\mathbb Z = \{\dots, -2, -1, 0, 1, 2, \dots\}$, or real numbers $\mathbb R$.
\item Vectors are sets containing $n$ of some type of object, like reals. We denote the set of all such sets using a superscript notation. For example, all $n$-dimensional vectors becomes $\mathbb R^n$.
\item With $x \in \mathcal S$ we denote that $x$ is an element of the set $\mathcal S$. This allows us to specify that a variable comes from a particular set (or, has a particular type), e.g.~$x \in \Reals^D$.
\item We sometimes use ``set builder'' notation. We did this informally above when defining $\mathbb N$! Usually this works by specifying elements with some property, e.g.~$\mathbf S = \{2n \,|\, n \in \mathbb N\}$, which means ``all the elements 2n such that $n$ is a natural number''. This creates the set of all even positive whole numbers.
\item We denote the union of two sets (the set with all elements that are in either set or both) as $A \cup B$. With set-builder notation this is $A \cup B = \{x\,|\,x\in A \vee x\in B\}$, where $\vee$ means ``or''.
\item We denote the intersection of two sets (the set of all elements that are in both stes) as $A \cap B = \{x\,|\,x\in A \wedge x\in B\}$.
\item For intervals of real numbers, we use brackets, $[,]$, to denote the elements in the set which are "greater than or equal to" and "less than or equal to" an element, respectively. We use parentheses, $(,)$ to denote a strict lower bound or upper bound on the set, respectively. E.g. $[1,5)$ is equivalent to $1 \leq x < 5, x\in\mathbb{R}$.
\item We use the symbol $\neg$ to denote the complement of a set. Given a set containing all elements under consideration $\Omega$, $\neg A$ contains all elements of $\Omega$ that are not in $A$, i.e.~$\neg A = \{x \in \Omega | x \notin A\}$. We can also denote this as $\neg A = \Omega\backslash A$.
\end{itemize}

\subsection{Probabilities}
In this course we will use the notation for probabilities that is common in machine learning. The main advantage is that this notation is shorter, although it does leave certain things implicit. We include this to reduce confusion.

Consider a probability space $(\Omega, \mathcal E, \mathbb P)$ with sample space $\Omega$ (all possible outcomes of a random procedure), event space $\mathcal E$ (the set of all sets of outcomes that we assign a probability to), and probability function $\mathbb P : \mathcal E \to [0, 1]$ (a function that assigns a probability to an event), with a random variable $X: \Omega \to \Reals^D$.
\begin{itemize}
\item With $\prob{E}$ we denote the probability of an event $E \in \mathcal E$, where $E$ is a set of outcomes.
\item Following the usual convention, we use the same notation when considering random variables, e.g.~$\prob{X < 2}$ is short for $\prob{\{s \in \Omega : X(s) < 2\}}$ (see \S6.1 in \courseprobstats).
\item We usually work directly with random variables, and specify all properties using a probability mass function (pmf) or probability density function (pdf). For a specific outcome of the random variable $\alpha$, we write:
\begin{align}
    &\prob{X=\alpha} = p_X(\alpha) && \text{for a pmf } p_X(\cdot) \,, \\
    &\prob{X \in [a, b]} = \int_a^b p_X(\alpha) d\alpha && \text{for a pdf $p_X(\cdot)$ with $\alpha \in \Reals$} \,, \\
    &\prob{X \in A} = \int_A p_X(\alpha) d\alpha && \text{for a pdf $p_X(\cdot)$ with $\alpha \in \Reals^D$}
    \,.
\end{align}
\item Sometimes we may write vectors in boldface, i.e.~$\mathbf x \in \Reals^D$. We won't always though, so keep track of how we define variables!
\item We generally denote outcomes of random variables without referring explicitly to the random variable itself. For example, when we refer to an outcome $\vx$, we implicitly know there is a random variable that can take this value. We usually denote this as the capital, for example here $X$.
\item Sometimes we abuse notation, and drop the random variable when denoting distributions when the argument of the function identifies it, e.g.~$p(\vx) = p_X(\vx)$.
\item If we want to be explicit about the random variable that we are evaluating the density/mass of, I will write e.g.~$p_{X,Y}(\vx,\vy) = p_{X|Y}(\vx|\vy)p_Y(\vy)$.
\item Expectations can be denoted in two ways:
\begin{align}
    &\Exp{X}{f(X)} && \text{to emphasise that X is random, if it is clear what its distribution is}\,, \\
    &\Exp{p(\vx)}{f(\vx)} && \text{to emphasise that we will be integrating over the distribution $p(\vx)$} \,.
\end{align}
In both cases this corresponds to the integral $\int p(\vx) f(\vx) \calcd\vx$.
\item Often, densities and pmfs can be discussed in exactly the same way, if we think of the density of a discrete RV as a sum of delta functions. I.e.~$p(\vx) = \sum_{o} \delta(\vx - \vx_o) p_o$, where $\{\vx_o\}$ is the set of discrete possible outcomes that $X$ can take, and $p_o$ are their corresponding probabilities. This allows us to write an expectation as an integral, regardless of whether the RV is continuous or discrete, because for discrete RVs we get:
\begin{align}
\Exp{p(\vx)}{f(\vx)} = \int p(\vx) f(\vx) \calcd\vx = \int \sum_o \delta(\vx - \vx_o) p_o f(\vx) \calcd\vx = \sum_o f(\vx_o)p_o \,.
\end{align}
(A delta function has the property that $\int_A \delta(\vx) \calcd\vx$ is 1 if $0 \in A$, and 0 otherwise. Linearity of integrals still holds. It can often be seen as the limit of a Gaussian distribution with zero variance.)
\end{itemize}


\section{Formula Sheet}
\begin{itemize}
\item Expectation identities for $X \in \Reals^D, Y \in \Reals^E$.
\begin{align}
\Exp{X}{AX} &= \Exp{X}{AX} = A\Exp{X}{X} \\
\Var{X}{X} &= \Exp{X}{XX\transpose} - \Exp{X}{X}\Exp{X}{X}\transpose \\
\Var{X}{AX} &= A\Var{X}{X}A\transpose \\
\Cov{X,Y}{X,Y} &= \Exp{X,Y}{XY\transpose} - \Exp{X}{X}\Exp{Y}{Y}\transpose \\
\Cov{X,Y}{X,Y} &= \Cov{X,Y}{Y,X}\transpose \\
\Cov{X,Y}{X,Y} &= 0 && \text{for } X \ci Y \\
\Exp{X,Y}{X + Y} &= \Exp{X}{X} + \Exp{Y}{Y} \\
\Var{X,Y}{X + Y} &= \Var{X}{X} + \Var{Y}{Y} && \text{for }X \ci Y \\
\Exp{X,Y}{XY\transpose} &= \Exp{X}{X}\Exp{Y}{Y}\transpose && \text{for } X \ci Y
\end{align}
\item For a RV $X \geq 0$, then $\Exp{X}{X} = 0$ if and only if $P(X = 0) = 1$.
\item Markov's inequality: For a RV $X \geq 0$, and $a > 0$, then $P(X \geq a) \leq \frac{\Exp{}{X}}{a}$.
\item Chebyshev's inequality: For a RV $X$ with finite mean, and finite non-zero variance, then for any $k>0$, $P(|X - \Exp{}{X}| \geq k\sigma) \leq \frac{1}{k^2}$.
\item Weak Law of Large Numbers: For a series of iid RVs $X_n$, we have for any $\epsilon > 0$ that
\begin{align}\lim_{n\to\infty} P(|\frac{1}{N}\sum_{n=1} X_n - \mu| < \epsilon) = 1 \,. \end{align}
\item Law of the Unconscious Statistician: If $Y = g(X)$ then $\Exp{Y}{Y} = \Exp{X}{g(X)}$.
\item Gaussian probability density function (pdf) with input $\vx \in \Reals^D$, denoted as  $\NormDist{\vx; \vmu, \covmat}$ is
\begin{align}
  p(\vx) = \NormDist{\vx; \vmu, \covmat} = (2\pi)^{-\frac{D}{2}}\detbar{\mathbf{\Sigma}}^{-\frac{1}{2}}\exp\left(-\frac{1}{2}(\vx - \vmu)\transpose\mathbf{\Sigma}^{-1}(\vx-\vmu)\right) \,.
\end{align}
\item For a joint Gaussian density
\begin{align}
\p{\begin{bmatrix}\vx \\ \vy\end{bmatrix}} = \NormDist{\begin{bmatrix}\vx \\ \vy\end{bmatrix}; \begin{bmatrix}\mx \\ \my\end{bmatrix}, \begin{bmatrix}\covx & \covxy \\ \covyx & \covy\end{bmatrix}} \label{eq:gauss-cond-joint} \,,
\end{align}
we have the conditional density
\begin{align}
\p{\vx\given\vy} = \NormDist{\vx; \quad\mx + \covxy\covy\inv(\vy-\my), \quad\covx - \covxy\covy\inv\covyx} \label{eq:gauss-cond} \,,
\end{align}
and the marginal density
\begin{align}
p(\vx) = \NormDist{\vx; \mx, \covx}\,.
\end{align}
\item Woodbury identity: $\left(A + UCV\right)\inv = A\inv - A\inv U\left(C\inv + VA\inv U\right)\inv VA\inv$.
\end{itemize}





\section{Warm-up Exercises}
To start, here are some exercises which test knowledge which is assumed in the course.

\subsection{Probability Theory}
We assume that you are familiar with probability theory up to the Computing 2nd year \courseprobstats{} course. Here are some questions to serve as a refresher. Students who are not familiar with this background should refer to the notes of \courseprobstats{} or relevant chapters of \citep{mml}. \textbf{We recommend you look at these questions when/before the course starts}. If you need a refresher, or if you do not know the notation, refer to the \courseprobstats{} notes, or discuss with a TA.

\begin{question}[Set Theory and Probability]
\label{q:setsprob}
Using the three axioms of probability show that
\begin{enumerate}[label=\alph*.]
    \item Write down the sample space of a dice. In your notation, use the set A to denote the event of a 3 or 4 occurring. What is the complement of $A$, denoted $\neg A$?
    \item For a problem about lengths, we have a sample space $\Omega = [0, 1]$. For $A = (0.3, 0.4]$, what is $\neg A$?
    \item $\prob{\neg  A} = 1 - \prob{A}$
    \item $\prob{\varnothing} = 0$, where $\varnothing$ is the empty set
    \item $0 \leq \prob{A} \leq 1$
    \item $A \subseteq B \implies \prob{A} \leq \prob{B}$
    
    \textit{Hint:} Consider the following definition. $B\backslash  A = \{x\in B: x\notin A\}$
    \item $\prob{A\cup B} = \prob{A} + \prob{B} - \prob{A\cap B}$
    \item (\textbf{*}) if $\{A_i\}_{i=1}^\infty \subseteq \Omega \text{ and } A_i \subseteq A_{i+1} \forall i$ then:
\[
P\left(\bigcup_{i=1}^{\infty} A_{i}\right) = \lim_{i\xrightarrow{}\infty} \prob{A_i}
\]
\textit{Hint:} Use axiom 3. \textbf{*}: The emphasis of this course isn't on these kinds of details, even though this should be doable with 1st-year calculus.
\item For two mutually exclusive events $A, B$, what is $\prob{A \cup B}$?
\end{enumerate}
See \citet[\S6.1.2]{mml} for a general overview, and \S4, \S\S5.1-5.4 of \courseprobstats{} for more details.
\end{question}

\begin{question}[Independent events]
\label{q:independent-events} 
\textbf{Independent events don't come up as much as independent random variables, so it's ok to just follow this answer, rather than spending lots of time on it.}
When tossing two coins (where we care about the order), we have a sample space $\Omega = \{HH, HT, TH, TT\}$.
\begin{enumerate}[label=\alph*.]
    \item What outcomes are contained in the event that corresponds to the the first coin being heads? We denote the event $E_{1H}$, and others similarly.
    \item If you assume that all outcomes have equal probability, show that $E_{1H}$ and $E_{2T}$ are independent.
    \item If you assume that $E_{1H}$ and $E_{2H}$ are independent and 0.5 each, show that all outomes must have equal probability.
\end{enumerate}
See \S5.3.3 in \courseprobstats{}.
\end{question}

\begin{question}[Random Variables]
\label{q:rv}
Consider throwing two fair dice.
\begin{enumerate}[label=\alph*.]
    \item What is the sample space for all outcomes that you can get from throwing two dice? We specify the probability of each outcome to be the same.
    \item Define two random variables $A,B$ which map the outcome to the face value on each die respectively. Find the probability mass function for $A$ from the probability on outcomes. The answer will work from the definition of a random variable, but you will probably intuitively get the right answer as well.
    \item Show that $A$ and $B$ are independent.
    \item Define the random variable $C = A + B$. Derive the probability mass function of $C$.
\end{enumerate}
See \S6 of \courseprobstats{}.
\end{question}


\begin{question}[Continuous Random Variables]
\label{q:crv}
Consider the random variable $X$ with a probability density $p(x) = C\cdot x$ when $x \in [0, 1]$ and $0$ elsewhere.
\begin{enumerate}[label=\alph*.]
    \item Calculate $C$.
    \item Calculate $\prob{0.3 \leq X \leq 0.75}$.
    \item Calculate $\prob{X \in [0.3, 0.75] \cup [0.8, 0.9]}$.
    \item Calculate $\Exp{X}{X}$, $\Exp{X}{X^2}$, $\Var{X}{X}$.
\end{enumerate}
Check your answers by performing numerical integration, e.g.~in Python.

See \S6.3, \S7 of \courseprobstats{} or \citet[\S 6.2.2]{mml}.
\end{question}


\begin{question}[Joint Discrete Random Variables]
\label{q:jdrv}
Consider two random variables $A,C$, where $A$ is the outcome of one die, and $C$ gives the sum of $A$ and the sum of another die $B$.
\begin{enumerate}[label=\alph*.]
    \item From intuition, write a table of $\prob{C=c|A=a}$, which we use to denote the probability of $C$ taking the value $c$, if we know that $A$ has taken the value $a$.
    \item Write a table of $\prob{C=c, A=a}$. To help you think it through, consider a tree of outcomes that can occur. This helps illustrate independence between outcomes, which helps you figure out when you can multiply probabilities.
    \item From the values in the table $\prob{C=c, A=a}$ find $\prob{2 \leq C \leq 4}$ and $\prob{2 \leq C \leq 4, 2 \leq A \leq 4}$.
\end{enumerate}
We will cover conditional probability more later, but for now just think it through.
\end{question}

\begin{question}[Multivariate Integration]
\label{q:mi}
Consider two continuous random variables $X,Y$ with joint density $p(x, y) = C\cdot (x^2 + xy)$ when $x \in [0, 1]$ and $y \in [0, 1]$, and $0$ elsewhere.
\begin{enumerate}[label=\alph*.]
    \item Find $C$.
    \item Find $\prob{0.3 \leq X \leq 0.5}$.
    \item Find $\prob{X < Y}$. Perform the integration twice in both orders, once integrating over x first, once by integrating over y first.
    \item \textbf{Bonus:} Convince yourself that you know how to do this for $p(x, y, z) = C\cdot (x^2 + xyz)$ as well.
\end{enumerate}
Check your answers by performing numerical integration, e.g.~in Python.
\end{question}

\begin{question}[Statistics Terminology] Recall the following statistical terminology.
\label{q:stats-term}
\begin{enumerate}[label=\alph*.]
    \item What is a statistic?
    \item What is an estimator?
    \item What is a consistent estimator?
    \item What is a sample?
\end{enumerate}
\end{question}

%%%%%%%%%%% Yingzhen's Linear Algebra warm-up questions %%%%%%%%%%

\input{linear_algebra_questions_warmup}


\section{Lecture 1: Probability, Vectors, Differentiation}
\begin{question}[Vector notation]
\label{q:vecnot}
We define the probability density on the vector $\vx \in \Reals^3$ with all elements $0 \leq x_k \leq 1$ as
\begin{align}
p(\vx) = \frac{1}{C} (x_1^2 + x_1x_2 + x_2^2 + 2x_2x_3) \,.
\end{align}
Put this into notation that only uses $\vx$ as a single whole vector.
\end{question}

\begin{question}[Noise conditional independence]
\label{q:noisecondind}
Consider the probability of the data in linear regression, for a fixed setting of the parameters $\vtheta$ and given inputs $\mat X \in \Reals^{D\times N}$ where $\mat X = \{\vx_1, \dots, \vx_N\}$:
\begin{align}
p(\vy|\vtheta,\mat X) = \NormDist{\vy; \vtheta\transpose X, \sigma^2 \eye}
\end{align}
Show that all $y_n$s are independent, for a fixed setting of the parameters $\vtheta$ and given inputs $\mat X$.
\end{question}

\begin{question}[Maximum likelihood revision]
\label{q:MLE-Niid}
For a Gaussian distribution with mean $\mu$ and variance $\sigma^2$.
\begin{enumerate}[label=\alph*.]
\item Derive the probability distribution for $N$ iid draws.
\item Derive the maximum likelihood estimator for the mean $\mu$ and variance $\sigma^2$.
\end{enumerate}
\end{question}

\begin{question}[Maximum likelihood and minimum loss]
\label{q:MLEReg}
Show that the solution to the Maximum Likelihood estimator for linear regression is the same as the minimum squared loss estimator.
\end{question}

\begin{question}[MML 5.1-5.3]
\label{q:chainrule}
This is revision. Compute the derivatives for w.r.t.~$x$ for
\begin{enumerate}[label=\alph*.]
\item $f(x) = \log (x^4) \sin (x^3)$
\item $f(x) = (1 + \exp(-x))^{-1}$
\item $f(x) = \exp\left(-\frac{(x-\mu)^2}{2\sigma^2}\right)$
\end{enumerate}
\end{question}

\section{Lecture 2: Vector Differentiation}
\begin{question}[Circle]
\label{q:circle}
Consider a vector function $\vx(t) = \begin{bmatrix}\cos t & \sin t\end{bmatrix}\transpose$.
\begin{enumerate}[label=\alph*.]
\item Draw the set of points that this function passes through.
\item To build intuition, draw the velocity vector at a few points by considering the direction that the point moves in.
\item Find the derivative $\calcd\vx / \calcd t$. Draw this vector for some point t.
\end{enumerate}
\end{question}

\begin{question}[Index notation] Turn the following matrix-vector expressions into index notation:
\label{q:index-notation}
\begin{multicols}{2}
\begin{enumerate}[label=\alph*.]
\item $\mat A \mat B \mat C \vx$
\item $\Tr(\mat A)$
\item $\Tr(\mat A \mat B)$
\item $\vy\transpose \mat A\transpose \vx$
\end{enumerate}
\end{multicols}
Turn the following index expressions back to matrix-vector notation:
\begin{multicols}{2}
\begin{enumerate}[label=\alph*.]
\item $\sum_{ijk} A_{ij}B_{jk}C_{ki}$
\item $b_i + \sum_j A_{ij}b_j$
\item $x_ix_j$
\item $\sum_j \delta_{ij}a_j$
\end{enumerate}
\end{multicols}
\end{question}

\begin{question}[Index notation proofs]
\label{q:ind-not-proof}
Using index notation, show that
\begin{enumerate}
\item $\vx\transpose \mat A\vy = \vy\transpose \mat A\vx$ if $\mat A$ is symmetric, i.e.~$\mat A = \mat A\transpose$.
\item $\vx\transpose\vy = \Tr(\vx\transpose\vy) = \Tr(\vy\transpose\vx)$, for $\vx,\vy\in\Reals^D$.
\item $\Tr(\mat A\mat B\mat C) = \Tr(\mat C\mat A\mat B)$.
\end{enumerate}
\end{question}

\begin{question}[MML 5.5-5.6]
\label{q:mml55-56}
First find the dimensions, then the Jacobian. It's probably easiest here to use index notation.
\begin{enumerate}[label=\alph*.]
\item $f(\vx) = \sin(x_1)\cos(x_2)$, find $\calcd f/\calcd\vx$.
\item $f(\vx) = \vx\transpose\vy$, find $\calcd f/\calcd\vx$.
\item $f(\vx) = \vx\vx\transpose$, find $\calcd f/\calcd\vx$.
\item $f(\vt) = \sin(\log(\vt\transpose\vt))$, find $\calcd f/\calcd\vt$.
\item $f(\mat X) = \Tr(\mat A \mat X \mat B)$ for $\mat A \in \Reals^{D\times E}$, $\mat X \in \Reals^{E\times F}$, $\mat B \in \Reals^{F\times D}$, find $\calcd f/\calcd\mat X$.
\end{enumerate}
\end{question}


\begin{question}[MML 5.7-5.8: Chain rule]
\label{q:chain-rule}
Comupte the derivatives $\calcd f /\calcd\vx$ of the following functions.
\begin{itemize}
\item First, write out the chain rule for the given decomposition.
\item Give the shapes of intermediate results, and make clear which dimension(s) will be summed over.
\item Provide expressions for the derivatives, and describe your steps in detail. Providing an expression means specifying everything up to the point where you could implement it.
\item Give the results in vector notation if you can. 
\end{itemize}
\begin{enumerate}[label=\alph*.]
\item $f(z) = \log(1+z), \qquad z = \vx\transpose\vx, \qquad \vx \in \Reals^D$.
\item $f(\vz) = \sin(\vz), \qquad \vz = \mat A\vx + \vb, \qquad \mat A \in \Reals^{E\times D}$. What sizes are $\vx$ and $\vb$?
\item $f(z) = \exp(-\frac{1}{2}z), \qquad z = \vy\transpose \mat S\inv \vy, \qquad \vy = \vx -\vmu$.
\item $f(\mat A) = \Tr(\mat A), \qquad \mat A = \vx\vx\transpose + \sigma^2 \mat I$.
\item $\vf(\vz) = \tanh(\vz), \qquad \vz = \mat A \vx + \vb, \qquad \mat A \in \Reals^{M\times N}$.
\item $f(\mat A) = \vx\transpose\mat A\vx, \qquad \mat A = \vx\vx\transpose\,.$
\end{enumerate}
Remember: Generally, scalar functions are applied elementwise to vectors/matrices.
\end{question}



\begin{question}[Hessian of Linear Regression]
\label{q:hessian}
For the stationary point of linear regression, find the Hessian, and prove that it is positive definite, perhaps by making some assumptions. Discuss your assumptions.
\end{question}


\section{Lecture 3: Automatic Differentiation}
\begin{question}[Product rule]
\label{q:autodiff-productrule} Consider the function $f(a, b) = a\cdot b$, where $a = a(x), b = b(x)$, i.e.~unspecified functions of $x$.
\begin{itemize}
\item Show that by following forward mode autodiff, you effectively calculate the product rule.
\item Show that if $a(x) = x, b(x) = x$, which means that the overall function $f(x) = x^2$, the gradient that is computed will be $2x$.
\end{itemize}
(Note from MvdW (autumn 2022): I somewhat messily described this on the board. The question is included here to provide a clearer explanation.)
\end{question}


\begin{question}[Multivariate Autodiff]
\label{q:autodiff} This is a rather big question that should test your understanding of all material in the first three lectures.
Consider the overall function $f(\boldsymbol \ell, \mat X)$ consisting of the parts:
\begin{align}
f &= \vy\transpose \left(\mat K_1 + \mat K_2\right)\inv \vy\,, \\
\mat K_a &= \exp\left(\mat \Lambda_a\right) \,, \\
\mat \Lambda_a &= -\frac{\mat D_a}{2\ell_a^2} \,, \\
\mat D_a &= (\mat X[:, \text{\texttt{None}}, a] - \mat X[\text{\texttt{None}}, :, a])^2 \,,
\end{align}
where we use \texttt{numpy} broadcasting notation in the final equation.
\begin{enumerate}[label=\alph*.]
\item Given $\boldsymbol \ell \in \Reals^2$ and $\mat X \in \Reals^{N\times 2}$, find the shape of all intermediate computations.
\item Draw the computational graph for $f(\boldsymbol\ell, \mat X)$.
\item For forward and reverse mode differentiation, state which intermediate derivatives are computed at each step, and their computational and memory costs.
\end{enumerate}
\end{question}

% Lecture 4: Probabilistic Modelling Principles 
\input{prob_modelling_questions}

% Lecture 5: Gradient Descent Convergence
\input{gradient_descent_questions}


\section{Lectures 6 \& 7: Multivariate Probability}

\begin{question}[Vector independence]
\label{q:vector-independence}
Consider the density on $\vx \in \Reals^4$ with all elements $0 \leq x_k \leq 1$ as
\begin{align}
p(\vx) = c \cdot \vx\transpose \begin{bmatrix} 0 & 0 & 0 & 0 \\ 1 & 0 & 1 & 0 \\ 0 & 0 & 0 & 0 \\ 1 & 0 & 1 & 0\end{bmatrix} \vx \,.
\end{align}
\begin{enumerate}[label=\alph*.]
\item Rewrite the density in terms of $\tilde\vx = [x_1, x_3, x_2, x_4]\transpose$. Note that you can do this by a substitution $\vx = \mat P \tilde\vx$, where $\mat P$ is a permutation matrix. You will see that you just need to swap the relevant rows and columns of the matrix. However, make sure that you understand the mathematical steps that really show this.
\item Divide up $\vx$ into two sub vectors $\vy = [x_2, x_4]\transpose$ and $\vz = [x_1, x_3]\transpose$. Show that $\vy \ci \vz$, i.e.~that they are independent.
\end{enumerate}
\end{question}

\input{multivariate_probability_questions}



\section{Lecture 8 \& 9: Generalisation, Test Sets, Monte Carlo}

\begin{question}[Independence of Losses] Under the iid assumption, the loss can be seen as a transformation of a random variable. Show that the losses are independent.
\end{question}

\begin{question}[Basic Monte Carlo Estimate]
\label{q:monte-carlo-estimate}
Consider the following integral over the indicator function $\mathbb I(\cdot)$, which takes value 1 when its argument evaluates to \texttt{True}:
\begin{align}
I = \int_{-1}^1\int_{-1}^1 \mathbb{I}(x^2 + y^2 < 1) \calcd x \calcd y \,.
\end{align}
\begin{enumerate}[label=\alph*.]
\item Write this integral as an expectation.
\item Construct a Monte Carlo estimate $\hat I$ for this integral.
\item Bonus: Implement this in Python and verify that the value converges to $\pi$.
\item Is $\hat I^2$ an unbiased estimator for $\pi^2$?
\end{enumerate}
\end{question}


\section{Lecture 10 \& 11: Bayesian Inference}
\begin{question}[Electrical Communication]
\label{q:electrical_communication}
Consider the electrical communication example from lectures, where we had a Gaussian distribution on the source voltage, i.e.~$p(S=s)= \NormDist{s; 0, 1}$. This time, we make multiple observations, i.e.~$V_n|s \overset{\mathrm{iid}}{\sim} \NormDist{s, \sigma^2}$.
\begin{enumerate}[label=\alph*.]
\item Write down Bayes' rule to find the posterior for $p(s|v_1, v_2, \dots v_N)$.
\item By completing the square, find the density of the posterior $p(s|v_1, v_2, \dots v_N)$.
\item Show that the likelihood function (which is a function of $s$!) can be rewritten as
\begin{align}p(v_1, v_2, \dots, v_N|s) = c\cdot p(\bar v|s) = c\cdot\NormDist{\bar v; s, \frac{\sigma^2}{N}}\,,\end{align}
where $\bar v = \frac{1}{N}\sum_{n=1}^N v_n$.
\item Find the joint distribution $p(\bar v, s)$.
\item Use the Gaussian conditioning rule to find $p(s|\bar v)$.
\item Reflect on which method you find easier.
\end{enumerate}
\end{question}


\begin{question}[Electrical Communication Errors]
\label{q:elec-comm-errors}
Consider the electrical communication example from lectures, where $p(v|s) = \NormDist{v; s, \sigma^2}$ and a Bernoulli $S$, i.e.~$p(S=s)= p^s(1-p)^{1-s}$. Assume that the noise distribution in the model is the same as that of the data generating process. Now consider a \emph{decision rule}, where we guess the transmitted signal using the rule $\hat S = \argmax_s p(s|v)$.

Now consider the true frequency of $S$ to follow $\pi(s) = \mathcal B(0.6)$. Calculate the probability of making an error $\mathbb P\left(\hat S = S\right)$, as a function of our prior probability $p$.

Hint: Remember the difference between the data generating distribution ($\mathbb P$/$\pi$), and our model ($P$/$p$). When calculating probabilities w.r.t.~the data generating distribution, $\hat{S}$ is a function of $S$.
\end{question}


\begin{question}[Vector Ordering in Gaussians]
Consider a joint Gaussian density on a vector $\vz$ that can be split up as $\vz = [\vx\transpose, \vy\transpose]\transpose$ (this notation denotes stacking):
\begin{align}
p(\vz) = \NormDist{\begin{bmatrix}\vx \\ \vy\end{bmatrix}; \begin{bmatrix}\va \\ \vb \end{bmatrix}, \begin{bmatrix}\mat A & \mat B \\ \mat B\transpose & \mat C\end{bmatrix}} \,.
\end{align}
Now consider the permuted vector $\vz' = [\vy\transpose, \vx\transpose]\transpose$. Show that the Gaussian distribution of $p(\vz')$ has a mean with rows, and a covariance matrix with swapped rows and columns.

Hint: Notice that $\vz'$ is a permuted version of $\vz$. We can write this mathematically as $\vz' = \mat P\vz$, where $\mat P$ is a permutation matrix:
\begin{align}
\mat P = \begin{bmatrix} 0 & \mat I \\ \mat I & 0\end{bmatrix}\,.
\end{align}

\textbf{Note:} This is an important skill! Notice that the Gaussian conditioning formula in the formula sheet is only written in one way.
\end{question}


\begin{question}[Woodbury Identity]
We saw that the two different ways of deriving the Gaussian posterior, gave two different results:
\begin{align}
p(\vtheta|\vy) &= \mathcal{N}\Big(\vtheta; \Phi(X)\transpose\left[\Phi(X)\Phi(X)\transpose + \sigma^2 \mat I_N\right]\inv\vy\,, &&\mat I_M - \Phi(X)\transpose\left[\Phi(X)\Phi(X)\transpose + \sigma^2 \mat I_N\right]\inv\Phi(X)\Big) \,, \nonumber\\
p(\vtheta|\vy) &= \mathcal{N} \Big(\vtheta; \left[\frac{1}{\sigma^2}\Phi(X)\transpose\Phi(X) + \mat I_M\right]\inv \frac{1}{\sigma^2}\Phi(X)\transpose\vy\,, &&\left[\frac{1}{\sigma^2}\Phi(X)\transpose\Phi(X) + \mat I_M\right]\inv \Big) \,.
\end{align}
Apply the Woodbury identity to $\left[\frac{1}{\sigma^2}\Phi(X)\transpose\Phi(X) + \mat I_M\right]\inv$ to show that the two solutions are equal.

\textbf{Note:} This is an excellent exercise for your matrix algebra skills. The main difficulty that most uninitiated have, is that multiplication no longer commutes. You need to be careful that you consistently pre/post multiply matrices.
\end{question}


\begin{question}[BLR Predictive]
For a Bayesian Linear Regression model:
\begin{enumerate}
\item Find $p(\vy^*,\vy)$.
\item Find $p(\vy^*|\vy)$.
\end{enumerate}
\end{question}

% lecture 12: bias variance tradeoff
\input{bias_variance_tradeoff_questions}

% lecture 13: pca
\input{pca_questions}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%



% \section{Lecture 1: Multivariate Probability}
% \begin{question}[Notation]
% \end{question}



\input{warm-up-answers}
\input{answers-lecture-1}
\input{question-16-17-18}
\input{answers-lecture2-diff}

\input{prob_modelling_answers}
\input{gradient_descent_answers}

\input{multivariate_probability_answers}

\input{answers-lecture-8}

% lecture 10 & 11: bayesian inference
\input{answers-lecture-10}




% lecture 12: bias variance tradeoff
\input{bias_variance_tradeoff_answers}

% lecture 13: pca
\input{pca_answers}

\printbibliography

\end{document}
